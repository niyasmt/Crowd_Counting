torchvision-0.12.0.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
torchvision-0.12.0.dist-info/LICENSE,,
torchvision-0.12.0.dist-info/METADATA,,
torchvision-0.12.0.dist-info/RECORD,,
torchvision-0.12.0.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
torchvision-0.12.0.dist-info/WHEEL,,
torchvision-0.12.0.dist-info/top_level.txt,,
torchvision-0.12.0.dist-info\LICENSE,sha256=wGNj-dM2J9xRc7E1IkRMyF-7Rzn2PhbUWH1cChZbWx4,1546
torchvision-0.12.0.dist-info\METADATA,sha256=Et4VlWwQDLV_0oSaKbPBKL6cJTmGlMuryMjagE8gXS8,10117
torchvision-0.12.0.dist-info\RECORD,,
torchvision-0.12.0.dist-info\WHEEL,sha256=fVcVlLzi8CGi_Ul8vjMdn8gER25dn5GBg9E6k9z41-Y,100
torchvision-0.12.0.dist-info\top_level.txt,sha256=ucJZoaluBW9BGYT4TuCE6zoZY_JuSP30wbDh-IRpxUU,12
torchvision/_C.pyd,,
torchvision/__init__.py,,
torchvision/__pycache__/__init__.cpython-39.pyc,,
torchvision/__pycache__/_internally_replaced_utils.cpython-39.pyc,,
torchvision/__pycache__/extension.cpython-39.pyc,,
torchvision/__pycache__/utils.cpython-39.pyc,,
torchvision/__pycache__/version.cpython-39.pyc,,
torchvision/_internally_replaced_utils.py,,
torchvision/datasets/__init__.py,,
torchvision/datasets/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/__pycache__/_optical_flow.cpython-39.pyc,,
torchvision/datasets/__pycache__/caltech.cpython-39.pyc,,
torchvision/datasets/__pycache__/celeba.cpython-39.pyc,,
torchvision/datasets/__pycache__/cifar.cpython-39.pyc,,
torchvision/datasets/__pycache__/cityscapes.cpython-39.pyc,,
torchvision/datasets/__pycache__/clevr.cpython-39.pyc,,
torchvision/datasets/__pycache__/coco.cpython-39.pyc,,
torchvision/datasets/__pycache__/country211.cpython-39.pyc,,
torchvision/datasets/__pycache__/dtd.cpython-39.pyc,,
torchvision/datasets/__pycache__/eurosat.cpython-39.pyc,,
torchvision/datasets/__pycache__/fakedata.cpython-39.pyc,,
torchvision/datasets/__pycache__/fer2013.cpython-39.pyc,,
torchvision/datasets/__pycache__/fgvc_aircraft.cpython-39.pyc,,
torchvision/datasets/__pycache__/flickr.cpython-39.pyc,,
torchvision/datasets/__pycache__/flowers102.cpython-39.pyc,,
torchvision/datasets/__pycache__/folder.cpython-39.pyc,,
torchvision/datasets/__pycache__/food101.cpython-39.pyc,,
torchvision/datasets/__pycache__/gtsrb.cpython-39.pyc,,
torchvision/datasets/__pycache__/hmdb51.cpython-39.pyc,,
torchvision/datasets/__pycache__/imagenet.cpython-39.pyc,,
torchvision/datasets/__pycache__/inaturalist.cpython-39.pyc,,
torchvision/datasets/__pycache__/kinetics.cpython-39.pyc,,
torchvision/datasets/__pycache__/kitti.cpython-39.pyc,,
torchvision/datasets/__pycache__/lfw.cpython-39.pyc,,
torchvision/datasets/__pycache__/lsun.cpython-39.pyc,,
torchvision/datasets/__pycache__/mnist.cpython-39.pyc,,
torchvision/datasets/__pycache__/omniglot.cpython-39.pyc,,
torchvision/datasets/__pycache__/oxford_iiit_pet.cpython-39.pyc,,
torchvision/datasets/__pycache__/pcam.cpython-39.pyc,,
torchvision/datasets/__pycache__/phototour.cpython-39.pyc,,
torchvision/datasets/__pycache__/places365.cpython-39.pyc,,
torchvision/datasets/__pycache__/rendered_sst2.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbd.cpython-39.pyc,,
torchvision/datasets/__pycache__/sbu.cpython-39.pyc,,
torchvision/datasets/__pycache__/semeion.cpython-39.pyc,,
torchvision/datasets/__pycache__/stanford_cars.cpython-39.pyc,,
torchvision/datasets/__pycache__/stl10.cpython-39.pyc,,
torchvision/datasets/__pycache__/sun397.cpython-39.pyc,,
torchvision/datasets/__pycache__/svhn.cpython-39.pyc,,
torchvision/datasets/__pycache__/ucf101.cpython-39.pyc,,
torchvision/datasets/__pycache__/usps.cpython-39.pyc,,
torchvision/datasets/__pycache__/utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/video_utils.cpython-39.pyc,,
torchvision/datasets/__pycache__/vision.cpython-39.pyc,,
torchvision/datasets/__pycache__/voc.cpython-39.pyc,,
torchvision/datasets/__pycache__/widerface.cpython-39.pyc,,
torchvision/datasets/_optical_flow.py,,
torchvision/datasets/caltech.py,,
torchvision/datasets/celeba.py,,
torchvision/datasets/cifar.py,,
torchvision/datasets/cityscapes.py,,
torchvision/datasets/clevr.py,,
torchvision/datasets/coco.py,,
torchvision/datasets/country211.py,,
torchvision/datasets/dtd.py,,
torchvision/datasets/eurosat.py,,
torchvision/datasets/fakedata.py,,
torchvision/datasets/fer2013.py,,
torchvision/datasets/fgvc_aircraft.py,,
torchvision/datasets/flickr.py,,
torchvision/datasets/flowers102.py,,
torchvision/datasets/folder.py,,
torchvision/datasets/food101.py,,
torchvision/datasets/gtsrb.py,,
torchvision/datasets/hmdb51.py,,
torchvision/datasets/imagenet.py,,
torchvision/datasets/inaturalist.py,,
torchvision/datasets/kinetics.py,,
torchvision/datasets/kitti.py,,
torchvision/datasets/lfw.py,,
torchvision/datasets/lsun.py,,
torchvision/datasets/mnist.py,,
torchvision/datasets/omniglot.py,,
torchvision/datasets/oxford_iiit_pet.py,,
torchvision/datasets/pcam.py,,
torchvision/datasets/phototour.py,,
torchvision/datasets/places365.py,,
torchvision/datasets/rendered_sst2.py,,
torchvision/datasets/samplers/__init__.py,,
torchvision/datasets/samplers/__pycache__/__init__.cpython-39.pyc,,
torchvision/datasets/samplers/__pycache__/clip_sampler.cpython-39.pyc,,
torchvision/datasets/samplers/clip_sampler.py,,
torchvision/datasets/sbd.py,,
torchvision/datasets/sbu.py,,
torchvision/datasets/semeion.py,,
torchvision/datasets/stanford_cars.py,,
torchvision/datasets/stl10.py,,
torchvision/datasets/sun397.py,,
torchvision/datasets/svhn.py,,
torchvision/datasets/ucf101.py,,
torchvision/datasets/usps.py,,
torchvision/datasets/utils.py,,
torchvision/datasets/video_utils.py,,
torchvision/datasets/vision.py,,
torchvision/datasets/voc.py,,
torchvision/datasets/widerface.py,,
torchvision/extension.py,,
torchvision/image.pyd,,
torchvision/io/__init__.py,,
torchvision/io/__pycache__/__init__.cpython-39.pyc,,
torchvision/io/__pycache__/_load_gpu_decoder.cpython-39.pyc,,
torchvision/io/__pycache__/_video_opt.cpython-39.pyc,,
torchvision/io/__pycache__/image.cpython-39.pyc,,
torchvision/io/__pycache__/video.cpython-39.pyc,,
torchvision/io/_load_gpu_decoder.py,,
torchvision/io/_video_opt.py,,
torchvision/io/image.py,,
torchvision/io/video.py,,
torchvision/libjpeg.dll,,
torchvision/libpng16.dll,,
torchvision/models/__init__.py,,
torchvision/models/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/__pycache__/alexnet.cpython-39.pyc,,
torchvision/models/__pycache__/convnext.cpython-39.pyc,,
torchvision/models/__pycache__/densenet.cpython-39.pyc,,
torchvision/models/__pycache__/efficientnet.cpython-39.pyc,,
torchvision/models/__pycache__/feature_extraction.cpython-39.pyc,,
torchvision/models/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/__pycache__/inception.cpython-39.pyc,,
torchvision/models/__pycache__/mnasnet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/__pycache__/regnet.cpython-39.pyc,,
torchvision/models/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/__pycache__/squeezenet.cpython-39.pyc,,
torchvision/models/__pycache__/vgg.cpython-39.pyc,,
torchvision/models/__pycache__/vision_transformer.cpython-39.pyc,,
torchvision/models/_utils.py,,
torchvision/models/alexnet.py,,
torchvision/models/convnext.py,,
torchvision/models/densenet.py,,
torchvision/models/detection/__init__.py,,
torchvision/models/detection/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/detection/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/anchor_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/backbone_utils.cpython-39.pyc,,
torchvision/models/detection/__pycache__/faster_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/fcos.cpython-39.pyc,,
torchvision/models/detection/__pycache__/generalized_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/image_list.cpython-39.pyc,,
torchvision/models/detection/__pycache__/keypoint_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/mask_rcnn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/retinanet.cpython-39.pyc,,
torchvision/models/detection/__pycache__/roi_heads.cpython-39.pyc,,
torchvision/models/detection/__pycache__/rpn.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssd.cpython-39.pyc,,
torchvision/models/detection/__pycache__/ssdlite.cpython-39.pyc,,
torchvision/models/detection/__pycache__/transform.cpython-39.pyc,,
torchvision/models/detection/_utils.py,,
torchvision/models/detection/anchor_utils.py,,
torchvision/models/detection/backbone_utils.py,,
torchvision/models/detection/faster_rcnn.py,,
torchvision/models/detection/fcos.py,,
torchvision/models/detection/generalized_rcnn.py,,
torchvision/models/detection/image_list.py,,
torchvision/models/detection/keypoint_rcnn.py,,
torchvision/models/detection/mask_rcnn.py,,
torchvision/models/detection/retinanet.py,,
torchvision/models/detection/roi_heads.py,,
torchvision/models/detection/rpn.py,,
torchvision/models/detection/ssd.py,,
torchvision/models/detection/ssdlite.py,,
torchvision/models/detection/transform.py,,
torchvision/models/efficientnet.py,,
torchvision/models/feature_extraction.py,,
torchvision/models/googlenet.py,,
torchvision/models/inception.py,,
torchvision/models/mnasnet.py,,
torchvision/models/mobilenet.py,,
torchvision/models/mobilenetv2.py,,
torchvision/models/mobilenetv3.py,,
torchvision/models/optical_flow/__init__.py,,
torchvision/models/optical_flow/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/optical_flow/__pycache__/raft.cpython-39.pyc,,
torchvision/models/optical_flow/_utils.py,,
torchvision/models/optical_flow/raft.py,,
torchvision/models/quantization/__init__.py,,
torchvision/models/quantization/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/googlenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/inception.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv3.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/shufflenetv2.cpython-39.pyc,,
torchvision/models/quantization/__pycache__/utils.cpython-39.pyc,,
torchvision/models/quantization/googlenet.py,,
torchvision/models/quantization/inception.py,,
torchvision/models/quantization/mobilenet.py,,
torchvision/models/quantization/mobilenetv2.py,,
torchvision/models/quantization/mobilenetv3.py,,
torchvision/models/quantization/resnet.py,,
torchvision/models/quantization/shufflenetv2.py,,
torchvision/models/quantization/utils.py,,
torchvision/models/regnet.py,,
torchvision/models/resnet.py,,
torchvision/models/segmentation/__init__.py,,
torchvision/models/segmentation/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/_utils.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/deeplabv3.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/fcn.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/lraspp.cpython-39.pyc,,
torchvision/models/segmentation/__pycache__/segmentation.cpython-39.pyc,,
torchvision/models/segmentation/_utils.py,,
torchvision/models/segmentation/deeplabv3.py,,
torchvision/models/segmentation/fcn.py,,
torchvision/models/segmentation/lraspp.py,,
torchvision/models/segmentation/segmentation.py,,
torchvision/models/shufflenetv2.py,,
torchvision/models/squeezenet.py,,
torchvision/models/vgg.py,,
torchvision/models/video/__init__.py,,
torchvision/models/video/__pycache__/__init__.cpython-39.pyc,,
torchvision/models/video/__pycache__/resnet.cpython-39.pyc,,
torchvision/models/video/resnet.py,,
torchvision/models/vision_transformer.py,,
torchvision/ops/__init__.py,,
torchvision/ops/__pycache__/__init__.cpython-39.pyc,,
torchvision/ops/__pycache__/_box_convert.cpython-39.pyc,,
torchvision/ops/__pycache__/_register_onnx_ops.cpython-39.pyc,,
torchvision/ops/__pycache__/_utils.cpython-39.pyc,,
torchvision/ops/__pycache__/boxes.cpython-39.pyc,,
torchvision/ops/__pycache__/deform_conv.cpython-39.pyc,,
torchvision/ops/__pycache__/feature_pyramid_network.cpython-39.pyc,,
torchvision/ops/__pycache__/focal_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/giou_loss.cpython-39.pyc,,
torchvision/ops/__pycache__/misc.cpython-39.pyc,,
torchvision/ops/__pycache__/poolers.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/ps_roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_align.cpython-39.pyc,,
torchvision/ops/__pycache__/roi_pool.cpython-39.pyc,,
torchvision/ops/__pycache__/stochastic_depth.cpython-39.pyc,,
torchvision/ops/_box_convert.py,,
torchvision/ops/_register_onnx_ops.py,,
torchvision/ops/_utils.py,,
torchvision/ops/boxes.py,,
torchvision/ops/deform_conv.py,,
torchvision/ops/feature_pyramid_network.py,,
torchvision/ops/focal_loss.py,,
torchvision/ops/giou_loss.py,,
torchvision/ops/misc.py,,
torchvision/ops/poolers.py,,
torchvision/ops/ps_roi_align.py,,
torchvision/ops/ps_roi_pool.py,,
torchvision/ops/roi_align.py,,
torchvision/ops/roi_pool.py,,
torchvision/ops/stochastic_depth.py,,
torchvision/transforms/__init__.py,,
torchvision/transforms/__pycache__/__init__.cpython-39.pyc,,
torchvision/transforms/__pycache__/_functional_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/_transforms_video.cpython-39.pyc,,
torchvision/transforms/__pycache__/autoaugment.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_pil.cpython-39.pyc,,
torchvision/transforms/__pycache__/functional_tensor.cpython-39.pyc,,
torchvision/transforms/__pycache__/transforms.cpython-39.pyc,,
torchvision/transforms/_functional_video.py,,
torchvision/transforms/_transforms_video.py,,
torchvision/transforms/autoaugment.py,,
torchvision/transforms/functional.py,,
torchvision/transforms/functional_pil.py,,
torchvision/transforms/functional_tensor.py,,
torchvision/transforms/transforms.py,,
torchvision/utils.py,,
torchvision/version.py,,
torchvision/zlib.dll,,
torchvision\_C.pyd,sha256=DbkBmezI0Jbu8fpyi_EsVf5nm7TOU3djqgWZZsydO3w,608256
torchvision\__init__.py,sha256=n4hjKSG4nxA5ggSOgvCQYM59mbECE_sP6__bBIxR7OM,3121
torchvision\_internally_replaced_utils.py,sha256=oas5PoFR4LlsQAe4-cHj-FNsehe-deWD4AMwq4Y672U,1801
torchvision\datasets\__init__.py,sha256=DVyXgYVKw8Skukf3FSAcxCOhQDEhcqBF33E47wMwO-o,2662
torchvision\datasets\_optical_flow.py,sha256=-Ayi05K8-m6fFITi4zq7J6GIHoX9_iK-Cca8sM7BP7Y,19832
torchvision\datasets\caltech.py,sha256=lIkdO0m_g-mb5utizusriECvRMkPkB9BAqsvXjKU3lE,8956
torchvision\datasets\celeba.py,sha256=Kxq9OMxVdHO93BuPAosxiwfThV8WZcAOISqr7yD-GdY,8483
torchvision\datasets\cifar.py,sha256=ztgzxlIjmlKDkw6IilircHAD7S2jQMeonApq9hpmwsg,6020
torchvision\datasets\cityscapes.py,sha256=P82nKEmVfWIz-82GamhN9h7HUtGsu7oldALIOzy8WFA,10458
torchvision\datasets\clevr.py,sha256=qkxuuAa-JLc4KhxV-Yi2Uz83e_67HEjAqPNE_0zdhHw,3504
torchvision\datasets\coco.py,sha256=ZBR-5RAAEYKg6wlScq0I--TTAq7bhQb4el-0sgbwIik,4067
torchvision\datasets\country211.py,sha256=JLbKNAFVntzqlL4f3-26tsWlMxV6vNzT4mMz4_KY5i0,2466
torchvision\datasets\dtd.py,sha256=PCR0PzI88tStHIQ8sS0qBaqaGlmNPGtPI7ngFvk1JL4,4039
torchvision\datasets\eurosat.py,sha256=qTI24oTjJVXlfs5VHjvjC_3If9s9joobS1X7mbxswII,2111
torchvision\datasets\fakedata.py,sha256=eEiZFwVkcd0Zo-eps8AMRUkUpGKj9eQDZ6hoDxqsln0,2548
torchvision\datasets\fer2013.py,sha256=UNVXG2b0S0ZlAQn9Qr7cRyD3A4iEnW21gFpqhKf2KR4,2837
torchvision\datasets\fgvc_aircraft.py,sha256=i0LjmYmRM1gcX-7b1KiJecB-kNsIgSKTnPFE8HwlmGg,4675
torchvision\datasets\flickr.py,sha256=9lDVN7LrE-3gEzXkJi1cHZ8Uvgkwilqgc26_4xPXyBw,5499
torchvision\datasets\flowers102.py,sha256=VtIlkzGreihWgs8hPwOlLC9TA_8iLorVK1y0JmIbkg4,4708
torchvision\datasets\folder.py,sha256=18bexIfkBp80cT88Pkkn5-fiYloBNZovykUXWFC9kKg,12246
torchvision\datasets\food101.py,sha256=deklWkwRS_tRq3JVZT_aRqs0xFtxiEw7Ay6j3Ch9bYg,3806
torchvision\datasets\gtsrb.py,sha256=3MpXIXkf9NiOa3Km75dRbjlx_uUqYtt-sQIGNKzT8gE,3845
torchvision\datasets\hmdb51.py,sha256=WJ6M6nQv2m7SPpzqBMVNYqo2JET3oJnWmubp2K9LQuQ,5804
torchvision\datasets\imagenet.py,sha256=t8ScaPpMZSnaOqHyKEu7rl9OxcFX0ntbMcvvDw4QaSU,8342
torchvision\datasets\inaturalist.py,sha256=O3ZO2jaOMS3eLaAmyF3MyRtqU_TB9iGEIixl7XFhgQc,10348
torchvision\datasets\kinetics.py,sha256=7-0_3myTjkPLHe9Phtb2ymZjCqkAFsBu9C32gxzIS3s,13426
torchvision\datasets\kitti.py,sha256=SelCq_D-xF-YW4ysDdVYiXWU2yzBJRti2vGxEoGiRFU,5755
torchvision\datasets\lfw.py,sha256=RLLVKg5_MvNdPvSPELnS4uYp6LMdp8ZqODs1NDIa6M0,10537
torchvision\datasets\lsun.py,sha256=OD81y83LGyy-1zxDPGMZl4ddq3YzieGnw1iyACoESYE,5842
torchvision\datasets\mnist.py,sha256=OXEpdzEGyaigGR7WWIxKn-Xtumf7JzBeey9n_OxBirg,21216
torchvision\datasets\omniglot.py,sha256=L5wZlBqNxTzLeRUfgN4eEiPgpSTDRF9xb7TrBmh_YBk,4193
torchvision\datasets\oxford_iiit_pet.py,sha256=5DoQJeGE7xKmXZTJrYX_YCS-B7pmubhs9ekLz-tzmjY,5197
torchvision\datasets\pcam.py,sha256=-xtECgRUKWbwAv1mAhSpSpS5ugIVY9vqUF-i3g5x80U,5245
torchvision\datasets\phototour.py,sha256=kiBA1S-06U0qWxwgG06lVFiqRpC12z-fzD_IOo1y8VA,8152
torchvision\datasets\places365.py,sha256=gdydOupGFXhkQBzq3zWi1DXZkejEUShyhwXCH3k8cvc,7371
torchvision\datasets\rendered_sst2.py,sha256=9XZgTir3Z4wdyYUF1VDeR0-xR4hyXI1Y0lyETA01Uj4,3643
torchvision\datasets\samplers\__init__.py,sha256=1FvVy3pTrv2oM9WN34eg0GFFJWPi7ImTG9pzESY7mFM,164
torchvision\datasets\samplers\clip_sampler.py,sha256=0o-f7dVWeYSeCM1vKAUO0Y3OSSIo0dqjy5N-e1ujD_c,6427
torchvision\datasets\sbd.py,sha256=__20dhP7RrdlpG6NHOob0NbHC6H8SePty-YhcOo1LtU,5377
torchvision\datasets\sbu.py,sha256=cbXwtiGJt7UxhHj7ymhPzGGNxyZS-d20ob30V27dvr0,4317
torchvision\datasets\semeion.py,sha256=P-FitWfYKqBHcghATdaX2qONxyQ-42wPyVR-fMEBrJI,3179
torchvision\datasets\stanford_cars.py,sha256=JcMB482ZVM0q3Xt3cYh_wOxpdwB7rP26QCihkjXUS2s,4964
torchvision\datasets\stl10.py,sha256=VO-28ofQe0pFInq-lY_9BBn7NR31kShCQ3NzVw9Ri_4,7470
torchvision\datasets\sun397.py,sha256=RO4HR7BFciUqtnw7hMoHXBcDPgNzIfxUwmmd3nWaBOc,2819
torchvision\datasets\svhn.py,sha256=2WjIP0v-q0wuSGyC3i1Mp_NUPJDv1Y109f6lNENyRyI,4911
torchvision\datasets\ucf101.py,sha256=v9G_pX8hJi6_RWi-gPatbGFzrCc7dv90djbVz1mlZG8,5345
torchvision\datasets\usps.py,sha256=PyFECpMSh0sMswf-rZFpzy-Uyopa2BLMEYKLJgGWBRE,3535
torchvision\datasets\utils.py,sha256=kWjS2GHHQ0v0CD35r4kWWFoi0IgxiRWo1kxAzSk0VDQ,16388
torchvision\datasets\video_utils.py,sha256=Re1bHf_4HTi0Yp1cH3mdyK7t297xKZ8ulYrv2scUr0w,16829
torchvision\datasets\vision.py,sha256=4zp2Jbnm0xdlkmyKQd3q9NVL6TQIuqEY7EVDVYNjHCo,4281
torchvision\datasets\voc.py,sha256=Q8_OI24xcTxdBElSxysy003F0p2fBcZrVBO4HY0_hWk,9580
torchvision\datasets\widerface.py,sha256=f_lLPPdZT9uM1924ClXF3uA2vO3ahkq-mQCzfNHsx7k,8278
torchvision\extension.py,sha256=BgZMnzzvuRw0hDufgWYIoldqcGIMMhzSDvqGQv3DZy4,3190
torchvision\image.pyd,sha256=RODYar0sz-YduVN-TwC1gljX-vtcgoFAWOxpM8P3DjQ,329728
torchvision\io\__init__.py,sha256=1dsiwLdmF8Oh1GpHAyvlmkbiF-zM-NJjwn3UAtzRpE8,8048
torchvision\io\_load_gpu_decoder.py,sha256=Pgne-druVJRVwEXRCX5rK75qsD3rZ6kOIbjZ7vNgLp8,174
torchvision\io\_video_opt.py,sha256=W_LUy3JEalzycbcA38rkSW085raPyta9AUHdDchOJIw,21041
torchvision\io\image.py,sha256=gYiieJzQeTNOicDR4ejPOzLJ19cKHUSwLkErOBEOfe0,9451
torchvision\io\video.py,sha256=FVMKHfoSmxoZKjMtWVFSDnOPPIc8mTnOAyGWXTZcc54,15742
torchvision\libjpeg.dll,sha256=RqPZ7l_awQdV8gwNfq4uF6qso45ravyjVQPBb8IOd_I,229376
torchvision\libpng16.dll,sha256=rsn_UBkP5HAfaNf4cN4KKTxtp6fZ_eQfH_HTODlTN9s,192512
torchvision\models\__init__.py,sha256=kXmapZtxM8fDgC5VMEprC3ZOQN71nZBJF87lTwXCXyQ,526
torchvision\models\_utils.py,sha256=MbB2hr6tx5uO4eQQfyqKBXvDsMLbCqB1nox_bKloNXM,3281
torchvision\models\alexnet.py,sha256=lXot5jSTFxf8LMRAdxdh78vcRqVaX3smDUvT0ri4vr8,2408
torchvision\models\convnext.py,sha256=rEpvJAgGW1EywngbrtFXViaQBxqX1H8W1wjDXglxuEY,10054
torchvision\models\densenet.py,sha256=CeJPR3FUzyVcOJwUOpDI7fL-qjttsL7CEgIKgk7VAdk,12835
torchvision\models\detection\__init__.py,sha256=pYNTEaMyOtds74pjqprs2Ww4FP923PRP3RIVL8ml04Y,175
torchvision\models\detection\_utils.py,sha256=IbGD734x7y5dXfEOnkiO08rEqnPdKp1uDFzrdxbOvXQ,19285
torchvision\models\detection\anchor_utils.py,sha256=oppv1Vo3ttGJkFtiECmHD1YeVytwQ9wDpq93d09OSHI,12044
torchvision\models\detection\backbone_utils.py,sha256=-bNjqrRfqYe1_4etNHbUws-ri6JDbwaNMAlah9cCbpw,9811
torchvision\models\detection\faster_rcnn.py,sha256=xOXEYjsuqwkWuhxaOq_Ra8dVvBF5DBYgwYlgwo6swPs,23840
torchvision\models\detection\fcos.py,sha256=kti-WkBS5s7DAVWcVTx7fsPx49Zu4Lc3TbCvETtTPj8,31798
torchvision\models\detection\generalized_rcnn.py,sha256=4-nFUkMKdCrGHl40pBt8WJ3mT1IdKhLKYH9rXgFyYfI,4615
torchvision\models\detection\image_list.py,sha256=IzFjxIaMdyFas1IHPBgAuBK3iYJOert5HzGurYJitNk,808
torchvision\models\detection\keypoint_rcnn.py,sha256=Gzu_j_Gh4jbLWt8ssn-Bs8mey68SsOTcXGFS5MskecY,18876
torchvision\models\detection\mask_rcnn.py,sha256=C2R7Q6trKXUv2elJkwptpwAf3JToDNhqL5xz8-qu_bk,18472
torchvision\models\detection\retinanet.py,sha256=0D6D6GuKs-sEUYJHREJXn6vSoiyrAAKEIOokJHC4Bdc,28331
torchvision\models\detection\roi_heads.py,sha256=LFZWBtgfTVCz7S6KhQabqvZwnw63tMej-G1MbAAQKHU,33401
torchvision\models\detection\rpn.py,sha256=434EBQ0_zc5H-3aJnMieYA3198-BJXAfXEmf1BU_iHs,15651
torchvision\models\detection\ssd.py,sha256=2hDRSCF9nfPr0FFF3Jy_A81_ll5p0iG9PRaay2y5QiY,27537
torchvision\models\detection\ssdlite.py,sha256=ix1YHbHu_FNw0HrPRNCBj5IMMlzidazBi8JM9hrze1I,10857
torchvision\models\detection\transform.py,sha256=Zdf-HURYZb8y6jBLeYRp3Yny4wQeJagZkJx_gd9OFLU,11831
torchvision\models\efficientnet.py,sha256=rtL-MHV7jtjl3elnJgXbrfT1fGmhr6iLJSioT9YeY6Q,15713
torchvision\models\feature_extraction.py,sha256=0luFu4sgsFpCUTUADZgQrOgTEQLqFet7MmoTJGum1mI,24775
torchvision\models\googlenet.py,sha256=qghk6zAXxcvBfvpXfoGnpwlxbUg8jWzvuwiPq3ge4ns,11784
torchvision\models\inception.py,sha256=aW5js5LLRH8inP5JhkQPO1WeRiXKgWI9q49V-nqgcmM,17915
torchvision\models\mnasnet.py,sha256=5X7qnroflzZbw9zbIBkSQW4JsSjVOGNHdCvu11Ampmg,11106
torchvision\models\mobilenet.py,sha256=0kQMa_r2edgOWoDJ9ZSYcrgDaQ_7quvZT3ZYE5g_OpM,201
torchvision\models\mobilenetv2.py,sha256=BDrJzVNo9D-F35mwg4w6mHKgZH74AQSXtgK7x0QBvE4,7794
torchvision\models\mobilenetv3.py,sha256=AsutzkQq2_jPhfHaZDfGrIoUn1tjFsahe0gvhFKGifg,12898
torchvision\models\optical_flow\__init__.py,sha256=m32EYcwAu7F3XcixQXh1eS_nexaj54cWhOuzk261-A0,48
torchvision\models\optical_flow\_utils.py,sha256=S1l1-IKzNcfAX6bA8Y946fLRLuOQxKzfGzAuvE3ZohM,1843
torchvision\models\optical_flow\raft.py,sha256=koy4xb_dU_BOKng9otq74RvujRiDQEj_kM-Ukzfg-LA,28476
torchvision\models\quantization\__init__.py,sha256=qvJKzv65FUXp4rakXYT4HNsTg-d5HYtW5NXvmwla5Qw,130
torchvision\models\quantization\googlenet.py,sha256=zIqpLlu0uMvuW-vvL6hYTBX5MjkI3yIj5aCjc1xxkCw,6249
torchvision\models\quantization\inception.py,sha256=mUIHcZ5d5MyeUmWjEIrJ2n2dUVBuTk5rfOzMOcNmrBE,9127
torchvision\models\quantization\mobilenet.py,sha256=ZX2PXCRTj7Jv7K4qXe5VnIn3cn-qTnYU01whuy3t5t0,203
torchvision\models\quantization\mobilenetv2.py,sha256=KWuT1mHqpN4_jjWa8dhIiqDMZ8CHSyJchSW4YkfeqZw,3493
torchvision\models\quantization\mobilenetv3.py,sha256=FRMfDKd6gPT07ftvgv1hygerjh01FbSwiQfQXrO7Oxg,6502
torchvision\models\quantization\resnet.py,sha256=GIzfeWUXhOpLuQcWDLWFLfVNv3FsZA0qXb-mhg85Hvc,6747
torchvision\models\quantization\shufflenetv2.py,sha256=yex0-Op4bjvhaJSdvhG7RKDqx1828HkKiy5xU-50UBQ,5213
torchvision\models\quantization\utils.py,sha256=Ij88l6toyO8MQi1w512Jt-yQ2Q9hK75-Z2SOjIzS6Zw,2109
torchvision\models\regnet.py,sha256=36b0EgDtPQJ0OcXT4LFObaL9fb6IyaZ8JCmMxrYU0SY,23594
torchvision\models\resnet.py,sha256=ad42xSZgw-_xT8Gv08LkwokEN_gtl43zaLywdiW9jbI,15794
torchvision\models\segmentation\__init__.py,sha256=FgTvuKZYTrBzKe2ILhn5qz2CqkGuGe8WrlYJaEbH2lc,69
torchvision\models\segmentation\_utils.py,sha256=3rZYMGlF99cfHNCFWG3SgDFImSqtMRyk90C08JayQAo,1612
torchvision\models\segmentation\deeplabv3.py,sha256=Sk-ZfinkD8z70dP1spCvNZSYi5UUvtmyA7Ps84RxSZ4,8947
torchvision\models\segmentation\fcn.py,sha256=IPH_HsQJFiVfZLUWHGIa11ggQ7WWJsgdSGE9ZteDqsk,4444
torchvision\models\segmentation\lraspp.py,sha256=RgbDq_mF7BGRjNyotCLNdRdyTmk__NEfq5ybXTwEesY,5097
torchvision\models\segmentation\segmentation.py,sha256=51MTvUGiDaNXP8DTGN2FwyEjuFiWvRaigKmlH03rStM,311
torchvision\models\shufflenetv2.py,sha256=x6EyuOFXrO73VtyGSniNuxA16JgIKpT8Qe77xNlGCCA,8525
torchvision\models\squeezenet.py,sha256=0l78mxCVpG_kcqCWpvmVIXWMHet2jnku0e-LkTWQTPQ,5800
torchvision\models\vgg.py,sha256=U-FsBC02oKK3mBPFpVV3hlwKp7iV2UVlkTGoJTVCv68,8511
torchvision\models\video\__init__.py,sha256=ZhPrHVNq45WUYG0zbGRcIGFmxCI7DXw87XIHwJxDZJ8,23
torchvision\models\video\resnet.py,sha256=jxyiOcAj73GssXpTQPocY-eeSbZcciYQyuD8FiLmaKI,11896
torchvision\models\vision_transformer.py,sha256=teZOL6SWQeJXiR_Kv4uezImBKAVsHvnzr7KadNrssVo,17371
torchvision\ops\__init__.py,sha256=f7GiObb3KqUKIRSkMbdaGMdLsFfORlVAeY1jtLWi6S0,1463
torchvision\ops\_box_convert.py,sha256=U0iPo5GpCvo8FGcnPwYIYw0upoEM_omm1CknBT4L0mo,2489
torchvision\ops\_register_onnx_ops.py,sha256=Fx20KTfXtSlMB8V1IxJ1xoP4PQZrzz3NVwvZQo7EVnE,3008
torchvision\ops\_utils.py,sha256=W9pWxwnIk6jGoE5LgYiDQKB_us33snMYHC-x6yiyUD8,2351
torchvision\ops\boxes.py,sha256=I4M2LcOKMxR0vTpn6Se9_RVgQPY9M8ZZZM-D5_b6pUY,13221
torchvision\ops\deform_conv.py,sha256=HJOCXx088QJkPz442otgznhwaOkPBdbc9f5h0u1hPWk,7185
torchvision\ops\feature_pyramid_network.py,sha256=TMw_Wv4cJMEP7iPmFD5xKdE7gb2cIvw--bCi57H1CcQ,7215
torchvision\ops\focal_loss.py,sha256=gsEmt86zBV5Jqcpwi5YP5Z7v-7tVPMnLh4J7B3WuQOU,1940
torchvision\ops\giou_loss.py,sha256=GzuIgK6DVfzC7Pfjc2tH2iBKyvhc8o6xzZWmgXIfsKY,2468
torchvision\ops\misc.py,sha256=xFz5q-InAsCaasGTzDvqurWDquyQFCjsZpmJG03BQjA,6701
torchvision\ops\poolers.py,sha256=uIIJ_G1wyGHGwvVKBQpAQIphbGehGvMnWZI_W8dDSfI,13064
torchvision\ops\ps_roi_align.py,sha256=zZZsiUnXKONwSIUHjlfJqSF7bDL-kA-fDiGiZoN4EcE,3682
torchvision\ops\ps_roi_pool.py,sha256=H_nzViQOpnls8hZ9a2mgnKacVqMQlb1E_s8pqAP-YBY,2907
torchvision\ops\roi_align.py,sha256=71Ikza-bVTzMbnRf14cro9YGvPUPcMMTP6bU3073C7k,4224
torchvision\ops\roi_pool.py,sha256=f6Xf8hrpR8VIzxU0fXU6yIYnDw5k8cGbNW9iE_Fo-mc,2961
torchvision\ops\stochastic_depth.py,sha256=9T4Zu_BaemKZafSmRwrPCVr5aaGH8tmzlsQAZO-1_-Y,2302
torchvision\transforms\__init__.py,sha256=WCNXTJUbJ1h7YaN9UfrBSvt--ST2PAV4sLICbTS-L5A,55
torchvision\transforms\_functional_video.py,sha256=hDgOI9du0ChhKg4z7skz7w9Xx5LPzXn-TgNBPObNPQA,3763
torchvision\transforms\_transforms_video.py,sha256=evDxN0j8PyG3Vu7V5YGJU8rQz0Xqi9lGWZ4yiFK8Wng,5081
torchvision\transforms\autoaugment.py,sha256=8ZnCmWGJ69vRebyumzRQSSJiCa60Qk5OAD4hfPFZfSY,21590
torchvision\transforms\functional.py,sha256=qekPc-9l1deT15pQPpJzrvmO8a8R-ZoGwHwqqHX8fNw,63835
torchvision\transforms\functional_pil.py,sha256=TrfDw4nIzQVMLzNLJmFBcgOJ-5wn7R8XqP7uOSFBTWw,12964
torchvision\transforms\functional_tensor.py,sha256=7GuN1Kb7XPxcHo781A2Bdnr-wj-VhyQJTCpvQDIWdJE,33946
torchvision\transforms\transforms.py,sha256=x2q3y3jPsO7Zmo0wJfApT2JRlBNJYdsKkBGx7s9n-NQ,82672
torchvision\utils.py,sha256=HQSRmUcDpx4RJFI-kIA_HN5bDe_EONLpG7vXnK9mleI,22100
torchvision\version.py,sha256=R1jiZ3rNobVwhrLf60JciUWc6stmv3DNNKHThjEWs1I,206
torchvision\zlib.dll,sha256=4tlDhqlDl2vb-ztXfk8WIhbyfNrMRvtmygwk4s9fRQM,84992
